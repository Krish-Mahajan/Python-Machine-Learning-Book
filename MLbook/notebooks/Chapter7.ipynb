{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator \n",
    "from sklearn.base import ClassifierMixin \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.externals import six \n",
    "from sklearn.base import clone \n",
    "from sklearn.pipeline import _name_estimators \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X,y = iris.data[50:,[1,2]] ,iris.target[50:] \n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train ,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "clf1 = LogisticRegression(penalty='l2',C=0.001,random_state=1)\n",
    "clf2 = DecisionTreeClassifier(max_depth=1,criterion='entropy',random_state=0)\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1,p=2,metric='minkowski')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 fold cross validation:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe1 = Pipeline([['sc',StandardScaler()],['clf',clf1]]) \n",
    "pipe3= Pipeline([['sc',StandardScaler()],['clf',clf3]])\n",
    "\n",
    "clf_labels = ['Logistic regression','Decision Tree','KNN']\n",
    "print('10 fold cross validation:\\n')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.87 (+/- 0.17) [Logistic regression]\n",
      "ROC AUC: 0.89 (+/- 0.16) [Decision Tree]\n",
      "ROC AUC: 0.88 (+/- 0.15) [KNN]\n"
     ]
    }
   ],
   "source": [
    "for clf , label in zip([pipe1,clf2,pipe3],clf_labels): \n",
    "    scores = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=10,scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(),scores.std(),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'algorithm.majority_vote_classifier' from '/home/krish.mahajan/Documents/PythonMachineLearning/MLbook/algorithm/majority_vote_classifier.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "import importlib\n",
    "sys.path.append('/home/krish.mahajan/Documents/PythonMachineLearning/MLbook') \n",
    "from algorithm import majority_vote_classifier\n",
    "importlib.reload( majority_vote_classifier ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mv_clf = majority_vote_classifier.MajorityVoteClassifier(classifiers =[pipe1,clf2,pipe3]) \n",
    "clf_labels += ['Majority Voting']\n",
    "all_clf = [pipe1,clf3,pipe3,mv_clf] \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.87 (+/- 0.17) [Logistic regression]\n",
      "ROC AUC: 0.86 (+/- 0.14) [Decision Tree]\n",
      "ROC AUC: 0.88 (+/- 0.15) [KNN]\n",
      "ROC AUC: 0.94 (+/- 0.13) [Majority Voting]\n"
     ]
    }
   ],
   "source": [
    "for clf,label in zip(all_clf,clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=10,scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(),scores.std(),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decisiontreeclassifier': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=1,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "             splitter='best'),\n",
       " 'decisiontreeclassifier__class_weight': None,\n",
       " 'decisiontreeclassifier__criterion': 'entropy',\n",
       " 'decisiontreeclassifier__max_depth': 1,\n",
       " 'decisiontreeclassifier__max_features': None,\n",
       " 'decisiontreeclassifier__max_leaf_nodes': None,\n",
       " 'decisiontreeclassifier__min_impurity_decrease': 0.0,\n",
       " 'decisiontreeclassifier__min_impurity_split': None,\n",
       " 'decisiontreeclassifier__min_samples_leaf': 1,\n",
       " 'decisiontreeclassifier__min_samples_split': 2,\n",
       " 'decisiontreeclassifier__min_weight_fraction_leaf': 0.0,\n",
       " 'decisiontreeclassifier__presort': False,\n",
       " 'decisiontreeclassifier__random_state': 0,\n",
       " 'decisiontreeclassifier__splitter': 'best',\n",
       " 'pipeline-1': Pipeline(memory=None,\n",
       "      steps=[['sc', StandardScaler(copy=True, with_mean=True, with_std=True)], ['clf', LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False)]]),\n",
       " 'pipeline-1__clf': LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'pipeline-1__clf__C': 0.001,\n",
       " 'pipeline-1__clf__class_weight': None,\n",
       " 'pipeline-1__clf__dual': False,\n",
       " 'pipeline-1__clf__fit_intercept': True,\n",
       " 'pipeline-1__clf__intercept_scaling': 1,\n",
       " 'pipeline-1__clf__max_iter': 100,\n",
       " 'pipeline-1__clf__multi_class': 'ovr',\n",
       " 'pipeline-1__clf__n_jobs': 1,\n",
       " 'pipeline-1__clf__penalty': 'l2',\n",
       " 'pipeline-1__clf__random_state': 1,\n",
       " 'pipeline-1__clf__solver': 'liblinear',\n",
       " 'pipeline-1__clf__tol': 0.0001,\n",
       " 'pipeline-1__clf__verbose': 0,\n",
       " 'pipeline-1__clf__warm_start': False,\n",
       " 'pipeline-1__memory': None,\n",
       " 'pipeline-1__sc': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'pipeline-1__sc__copy': True,\n",
       " 'pipeline-1__sc__with_mean': True,\n",
       " 'pipeline-1__sc__with_std': True,\n",
       " 'pipeline-1__steps': [['sc',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)],\n",
       "  ['clf',\n",
       "   LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "             penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "             verbose=0, warm_start=False)]],\n",
       " 'pipeline-2': Pipeline(memory=None,\n",
       "      steps=[['sc', StandardScaler(copy=True, with_mean=True, with_std=True)], ['clf', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "            weights='uniform')]]),\n",
       " 'pipeline-2__clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "            weights='uniform'),\n",
       " 'pipeline-2__clf__algorithm': 'auto',\n",
       " 'pipeline-2__clf__leaf_size': 30,\n",
       " 'pipeline-2__clf__metric': 'minkowski',\n",
       " 'pipeline-2__clf__metric_params': None,\n",
       " 'pipeline-2__clf__n_jobs': 1,\n",
       " 'pipeline-2__clf__n_neighbors': 1,\n",
       " 'pipeline-2__clf__p': 2,\n",
       " 'pipeline-2__clf__weights': 'uniform',\n",
       " 'pipeline-2__memory': None,\n",
       " 'pipeline-2__sc': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'pipeline-2__sc__copy': True,\n",
       " 'pipeline-2__sc__with_mean': True,\n",
       " 'pipeline-2__sc__with_std': True,\n",
       " 'pipeline-2__steps': [['sc',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)],\n",
       "  ['clf',\n",
       "   KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "              metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "              weights='uniform')]]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=MajorityVoteClassifier(classifiers=[Pipeline(memory=None,\n",
       "     steps=[['sc', StandardScaler(copy=True, with_mean=True, with_std=True)], ['clf', LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', ra...ski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')]])],\n",
       "            vote='classlabel', weights=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'pipeline-1__clf__C': [0.001, 0.1, 100.0], 'decisiontreeclassifier__max_depth': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'decisiontreeclassifier__max_depth':[1,2],\n",
    "         'pipeline-1__clf__C':[0.001,0.1,100.0]} \n",
    "\n",
    "grid = GridSearchCV(estimator=mv_clf ,param_grid=params,cv=10,scoring='roc_auc')\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933+/-0.07 {'pipeline-1__clf__C': 0.001, 'decisiontreeclassifier__max_depth': 1}\n",
      "0.947+/-0.07 {'pipeline-1__clf__C': 0.1, 'decisiontreeclassifier__max_depth': 1}\n",
      "0.973+/-0.03 {'pipeline-1__clf__C': 100.0, 'decisiontreeclassifier__max_depth': 1}\n",
      "0.947+/-0.07 {'pipeline-1__clf__C': 0.001, 'decisiontreeclassifier__max_depth': 2}\n",
      "0.947+/-0.07 {'pipeline-1__clf__C': 0.1, 'decisiontreeclassifier__max_depth': 2}\n",
      "0.973+/-0.03 {'pipeline-1__clf__C': 100.0, 'decisiontreeclassifier__max_depth': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krish.mahajan/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "for params, mean_score, scores in grid.grid_scores_: \n",
    "    print(\"%0.3f+/-%0.2f %r\" % (mean_score,scores.std()/2 ,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'pipeline-1__clf__C': 100.0, 'decisiontreeclassifier__max_depth': 1}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters: %s' % grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying bagging to classify samples in wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/'\n",
    "                      'ml/machine-learning-databases/wine/wine.data',\n",
    "                      header=None)\n",
    "\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
    "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "                   'Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop 1 class \n",
    "df_wine= df_wine[df_wine['Class label'] !=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_wine['Class label'].values \n",
    "X = df_wine[['Alcohol','OD280/OD315 of diluted wines']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split \n",
    "le = LabelEncoder() \n",
    "y = le.fit_transform(y) \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier  \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "tree = DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=None) \n",
    "bag = BaggingClassifier(base_estimator=tree,n_estimators=500,max_samples=1.0,max_features=1.0,bootstrap=True,bootstrap_features=False,\n",
    "                       n_jobs=1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train/test accuracies 1.000/0.833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "tree = tree.fit(X_train,y_train)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "tree_train = accuracy_score(y_train,y_train_pred)\n",
    "tree_test = accuracy_score(y_test,y_test_pred)\n",
    "\n",
    "print('Decision tree train/test accuracies %.3f/%.3f' %(tree_train,tree_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train/test accuracies 1.000/0.917\n"
     ]
    }
   ],
   "source": [
    "bag = bag.fit(X_train,y_train)\n",
    "y_train_pred = bag.predict(X_train)\n",
    "y_test_pred = bag.predict(X_test)\n",
    "bag_train = accuracy_score(y_train,y_train_pred)\n",
    "bag_test = accuracy_score(y_test,y_test_pred) \n",
    "\n",
    "print('Decision tree train/test accuracies %.3f/%.3f' %(bag_train,bag_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying AdaBoost using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "tree = DecisionTreeClassifier(criterion='entropy',random_state=1,max_depth=1) \n",
    "ada = AdaBoostClassifier(base_estimator = tree, n_estimators =500,learning_rate =0.1,random_state=1) \n",
    "tree = tree.fit(X_train,y_train)\n",
    "ada = ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree train/test accuracies 0.916/0.875\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "tree_train = accuracy_score(y_train,y_train_pred)\n",
    "tree_test = accuracy_score(y_test,y_test_pred) \n",
    "\n",
    "print('Decision tree train/test accuracies %.3f/%.3f' %(tree_train,tree_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost train/test accuracies 1.000/0.917\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = ada.predict(X_train)\n",
    "y_test_pred = ada.predict(X_test)\n",
    "ada_train = accuracy_score(y_train,y_train_pred)\n",
    "ada_test = accuracy_score(y_test,y_test_pred)  \n",
    "\n",
    "\n",
    "print('Adaboost train/test accuracies %.3f/%.3f' %(ada_train,ada_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
